# -*- coding: utf-8 -*-
"""Track Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v9hTddjgbPdjnEWb0LfNOukMuB_z0c9Z
"""

!pip install -U crawl4ai
!pip install nest_asyncio

"""## Crawl the URL and save the output in a file"""

import crawl4ai
print(crawl4ai.__version__.__version__)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !crawl4ai-setup

!crawl4ai-doctor

url = "https://www2.deloitte.com/us/en/insights/economy/global-economic-outlook/weekly-update/weekly-update-2023-10.html"

import asyncio
import nest_asyncio
nest_asyncio.apply()

from crawl4ai import AsyncWebCrawler, CacheMode, BrowserConfig, CrawlerRunConfig, CacheMode

async def simple_crawl():
    crawler_run_config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url=url,
            config=crawler_run_config
        )
        # Process the output
        output = result.markdown

        # Write the output to a markdown file
        with open("output.md", "w", encoding="utf-8") as md_file:
            md_file.write(output)

        print("Output saved to output.md")

asyncio.run(simple_crawl())



"""## RAG"""

!pip install langchain langchain_community langchain_core faiss-cpu openai unstructured

from langchain_community.document_loaders import UnstructuredMarkdownLoader

markdown_path = "output.md"
loader = UnstructuredMarkdownLoader(markdown_path)

data = loader.load()

data[0]

from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)

texts = text_splitter.split_documents(data)

print(texts[1])

!pip install langchain_openai

from langchain_openai import OpenAIEmbeddings

import os
from google.colab import userdata

os.environ["OPENAI_API_KEY"] = userdata.get("OPENAI_API_KEY")

embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

import faiss
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores import FAISS

vectorstore = FAISS.from_documents(texts, embeddings)

"""## Persist Vectors"""

vectorstore.save_local("faiss_index")

"""## Retrieval Chains"""

from langchain import PromptTemplate
from langchain.chains import RetrievalQA

prompt_template = """
You are an AI assistant tasked with answering questions based solely
on the provided context. Your goal is to generate a comprehensive answer
for the given question using only the information available in the context. Follow these instructions carefully:

1. First, you will be given a context to work with:

context: {context}

2. Then, you will be presented with a question:

question: {question}

3. Carefully analyze the context:
   - Read through the entire context thoroughly.
   - Identify key information relevant to the question.
   - Note any specific facts, figures, or statements that
   directly relate to the question.

4. Generate your answer:
   - Use only the information provided in the context.
   - Do not include any external knowledge or assumptions not
   present in the given context.
   - If the context does not contain enough information to fully
   answer the question, state this clearly in your response.
   - Ensure your answer is comprehensive and addresses all aspects
    of the question that can be answered using the context.

5. Format your answer in Markdown:
   - Use appropriate Markdown syntax to structure your response.
   - Utilize headings, bullet points, or numbered lists where
   applicable to organize information clearly.
   - If quoting directly from the context, use quotation marks
   and consider using blockquote formatting (>).

6. Provide your final answer:
   - Begin your response with <response> and end it with </response>.
   - Ensure your entire answer, including all Markdown formatting,
   is contained within these tags.

Remember, your task is to answer the question based solely on the
given context. Do not include any information or knowledge that
is not explicitly stated in the provided context.
"""

prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])

new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

new_db

retriever = new_db.as_retriever(search_kwargs={"k":5})

chain_type_kwargs = {"prompt": prompt}

from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0.3,
    max_tokens=1000
)

qa = RetrievalQA.from_chain_type(llm=llm,
                                 chain_type="stuff",
                                 retriever=retriever,
                                 return_source_documents=True,
                                 chain_type_kwargs=chain_type_kwargs,
                                 verbose=True)

test_query = "Can you provide an overview of the US economy?"

response = qa(test_query)
print(response)
answer = response['result']
source_document = response['source_documents'][0].page_content
doc = response['source_documents'][0].metadata['source']

answer

"""## Batch Processing"""

with open("questions.txt", "r") as qfile:
    questions = [line.strip() for line in qfile if line.strip()]

responses = []

for idx, question in enumerate(questions, start=1):
    response = qa(question)
    answer = response["result"]
    formatted_response = f"<response_{idx}>\n{answer}\n</response_{idx}>"
    responses.append(formatted_response)

with open("responses.txt", "w") as rfile:
    rfile.write("\n\n".join(responses))

